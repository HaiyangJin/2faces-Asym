---
title: "Two faces of holistic face processing -- analyses and results"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output: 
  html_document:
    code_folding: hide
    number_sections: true
    toc: true
    toc_depth: 4
    toc_float: true
---

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

```{r global_options, echo = FALSE, include = FALSE}
options(width = 1500)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      include = TRUE, cache = FALSE, tidy = FALSE, 
                      size = "big", fig.width=8, fig.asp=0.7)
xaringanExtra::use_clipboard()
```

# Preparations
```{r setup}
## load libraries
library(tidyverse)
library(readxl)
library(lme4)
library(lmerTest)
library(optimx)
library(emmeans)
library(ggpubr)
```

```{r}
folder_lmm <- "lmm_output"
ylimit_cf_d <- c(-.5, 3.2)
ylimit_cf_fi_d <- c(-1.1, 1.1)
ylimit_cf_rt <- c(650, 1150)
ylimit_cf_fi_rt <- c(-100, 100)

# colors
con_color <- c("#e28743", "#0000ff")  #ffb14e #e3b342
sig_color <- "red"
```

## Load data 
```{r read the data file}
# list filenames
file1_list <- list.files(file.path("data", "1"), pattern = "*.xlsx", full.names = TRUE)
file2_list <- list.files(file.path("data", "2"), pattern = "*.xlsx", full.names = TRUE)

# load data
df_raw_E1 <- sapply(file1_list, read_excel, na = "NA", simplify = FALSE) %>% bind_rows(.id = "id") 
df_raw_E2 <- sapply(file2_list, read_excel, na = "NA", simplify = FALSE) %>% bind_rows(.id = "id")
  
# combine data from the two experiments
df_raw_E1_temp <- df_raw_E1 %>% 
  select(-c(SubTrial)) %>% 
  mutate(Probability = 0.5,
         targetDuration = 200, # fix a bug in exp
         Participant = Participant + 100)

df_raw_E2_temp <- df_raw_E2 %>% 
  select(-c(Age, Gender, Ethnicity, Block, FaceIndex)) %>% 
  mutate(Participant = Participant + 200,
         Probability = if_else(grepl("75TopCue", Experiment), 0.75, 0.25))

df_raw <- bind_rows(df_raw_E1_temp, df_raw_E2_temp)
  
str(df_raw)
```

## Tidy data
```{r select certain rows and columns from the data, and calculate the Z value for reaction times}
df_tidy <- df_raw %>% 
  filter(!is.na(thisResponse)) %>%  # remove NA trials based on responses
  mutate(Cue = if_else(CuedHalf == "T", "top", "bottom"),
         Congruency = if_else(Congruency == "C", "congruent", "incongruent"),
         Alignment = if_else(Alignment == "A", "aligned", "misaligned"),
         SameDifferent = if_else(SameDifferent == "S", "same", "different"),
         Participant = as_factor(Participant),
         Cue = factor(Cue, levels = c("top", "bottom")),
         Congruency = factor(Congruency, levels = c("congruent", "incongruent")),
         Alignment = as_factor(Alignment),
         SameDifferent = factor(SameDifferent, levels = c("same", "different")),
         Probability = as_factor(Probability),
         Resp = if_else(thisResponse == "S", 1, 0), # if this response is "same"
         RT = round(reactionTime * 1000+200)) # plus the duration of target faces
```

+ Cue: top vs. bottom
+ Congruency: congruent vs. incongruent
+ Alignment: aligned vs. misaligned
+ Identity (SameDifferent): same vs. different

Number of trials for each participant:
```{r}
# Trial numbers in each condition
df_tidy %>% 
  group_by(Participant) %>% 
  summarize(nTotal = n()) 

# For 3 participants in E1, one trail was removed due to no response recorded.
```

```{r}
# set successive difference coding for fixed effects
contrasts(df_tidy$Cue) <- MASS::contr.sdif(nlevels(df_tidy$Cue)) 
contrasts(df_tidy$Congruency) <- MASS::contr.sdif(nlevels(df_tidy$Congruency)) 
contrasts(df_tidy$Alignment) <- MASS::contr.sdif(nlevels(df_tidy$Alignment))
contrasts(df_tidy$SameDifferent) <- MASS::contr.sdif(nlevels(df_tidy$SameDifferent))

# set successive difference coding for random effects
df_lmm <- df_tidy %>% 
  mutate(
    Cue_C = if_else(Cue == "top", -.5, .5),
    Con_C = if_else(Congruency == "congruent", -.5, .5),
    Ali_C = if_else(Alignment == "aligned", -.5, .5),
    Sam_C = if_else(SameDifferent == "same", -.5, .5),
    
    Cue_Con = Cue_C * Con_C,
    Cue_Ali = Cue_C * Ali_C,
    Cue_Sam = Cue_C * Sam_C,
    Con_Ali = Con_C * Ali_C,
    Con_Sam = Con_C * Sam_C,
    Ali_Sam = Ali_C * Sam_C,
    
    Cue_Con_Ali = Cue_Con * Ali_C,
    Cue_Con_Sam = Cue_Con * Sam_C,
    Cue_Ali_Sam = Cue_Ali * Sam_C,
    Con_Ali_Sam = Con_Ali * Sam_C,
    
    Cue_Con_Ali_Sam = Cue_Con_Ali * Sam_C
  )

# save the data (for fitting model in cluster)
# save(df_lmm, file = file.path("data", "df_lmm.RData"))
```

## Steps to obtain the optimal model

1. If the maximal model did not converge, correlations between random effects were removed, making the zero-correlation-parameter (ZCP) model. 
2. Principal component analysis implemented with `rePCA()` function was then used to identify random effects that explained less than 0.1% of the total variances; they were removed from the ZCP model to make the reduced model. 
3. The extended model was built by adding back the correlations between random effects in the reduced model. 
4. If the extended model did not converge, the random effects that explained less than 1% of total variances were identified by `rePCA()` and removed to make the updated extended model; this step was iterated until an extended model converged. 
5. The converged extended model was then compared to the reduced model via `anova()` function and the model that explained the data better (with smaller Bayesian Information Criterion) was used as the optimal model. 
6. All follow-up analyses were performed on the optimal model. 

## Effects of interest

Two sets of analyses were conducted to examine (1) the composite effect and (2) facilitation and interference for each dependent variable.

### Behavioral choices
For behavioral choices, signal detection models were implemented by GLMM with binomial error distribution and `probit` link, in which sensitivity d’ was defined as z(hits) – z(false alarms) and `same` in `SameDifferent` was treated as “signal”. 

a. The composite effect was tested by:
    1. The Congruency effect for aligned faces in sensitivity d’, i.e., the interaction between Congruency and Correct Response in the aligned condition 
    2. The differences of the Congruency effects (congruent – incongruent) between the aligned and misaligned conditions in sensitivity d’ (this effect was denoted as the interaction between Congruency and Alignment of d’ in the results), i.e., the interaction between Congruency, Alignment and Correct Response. 
b. Facilitation and interference effects were examined by pairwise comparisons between aligned and misaligned composites in sensitivity d’, i.e., interaction between Alignment and Correct Response for congruent and incongruent trials separately. 

### Response times
For (correct) response times, GLMM with `lognormal` transformation was applied. 

a. The composite effect was tested by:
    1. The Congruency effect for aligned composites;
    2. The interaction between Congruency and Alignment.
b. Facilitation and interference effects were tested by pairwise comparisons between aligned and misaligned composites in congruent and incongruent conditions separately

# Experiment 1
```{r only keep E1}
df_lmm_E1 <- df_lmm %>% 
  filter(Experiment == "109_cue") %>% 
  droplevels()

# save(df_lmm_E1, file = file.path("data", "df_lmm_E1.RData"))
```
There were `r nlevels(df_lmm_E1$Participant)` participants in Experiment 1. 

## Behavioral choices (d')
### Fitting the generalized mixed models
#### The maximal model
```{r resp max d E1}

# file_E1_resp_max <- file.path(folder_lmm, "E1_Resp_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_E1_resp_max)) {
#   glmm_E1_resp_max <- glmer(
#     Resp ~ Cue * Congruency * Alignment * SameDifferent + 
#       (Cue * Congruency * Alignment * SameDifferent | Participant), # Con_Ali_Sam
#     family = binomial(link = "probit"),
#     data = df_lmm_E1,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_E1_resp_max, file = file_E1_resp_max)
# } else {
#   load(file_E1_resp_max)
# }
# 
# print(summary(glmm_E1_resp_max), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r resp zcp E1}
file_E1_resp_zcp <- file.path(folder_lmm, "E1_Resp_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file_E1_resp_zcp)) {
  glmm_E1_resp_zcp <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Ali + Con_Sam + Ali_Sam +
         Cue_Con_Ali + Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E1_resp_zcp, file = file_E1_resp_zcp)
} else {
  load(file_E1_resp_zcp)
}

print(summary(glmm_E1_resp_zcp), corr = FALSE)
```

#### The reduced model
```{r PCA analysis for resp zcp lmm E1}
summary(rePCA(glmm_E1_resp_zcp))
```

`Con_Ali`, `Cue_Con_Ali`, `Ali_Sam`, and `Con_C` were removed from extended model (`glmm_E1_resp_zcp`) due to that the variances they explained were smaller than 0.1%, making `glmm_resp_rdc`.

```{r resp rdc E1}
file_E1_resp_rdc <- file.path(folder_lmm, "E1_Resp_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file_E1_resp_rdc)) {
  glmm_E1_resp_rdc <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (Cue_C + Ali_C + Sam_C + # Con_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + 
         Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + # Cue_Con_Ali + 
         Cue_Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E1_resp_rdc, file = file_E1_resp_rdc)
} else {
  load(file_E1_resp_rdc)
}

print(summary(glmm_E1_resp_rdc), corr = FALSE)
```

#### The extended model
```{r resp etd E1}
file_E1_resp_etd <- file.path(folder_lmm, "E1_Resp_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_E1_resp_etd)) {
  glmm_E1_resp_etd <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (Cue_C + Ali_C + Sam_C + # Con_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + 
         Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + # Cue_Con_Ali + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E1_resp_etd, file = file_E1_resp_etd)
} else {
  load(file_E1_resp_etd)
}

print(summary(glmm_E1_resp_etd), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd))
```

`Cue_Con`, `Ali_C`, `Cue_Ali`, and `Intercept` were removed from the extended model.

```{r resp etd1 E1}
file_E1_resp_etd1 <- file.path(folder_lmm, "E1_Resp_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_E1_resp_etd1)) {
  glmm_E1_resp_etd1 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + Cue_C + Sam_C + # Con_C + Ali_C + 
         Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + # Cue_Con_Ali + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E1_resp_etd1, file = file_E1_resp_etd1)
} else {
  load(file_E1_resp_etd1)
}

print(summary(glmm_E1_resp_etd1), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd1))
```

`Cue_Ali_Sam`, and `Cue_C` were removed from extended1 model.

```{r resp etd2 E1}
file_E1_resp_etd2 <- file.path(folder_lmm, "E1_Resp_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_E1_resp_etd2)) {
  glmm_E1_resp_etd2 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + Sam_C + # Con_C + Ali_C + Cue_C + 
         Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + Con_Ali_Sam + # Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_resp_etd2, file = file_E1_resp_etd2)
} else {
  load(file_E1_resp_etd2)
}

print(summary(glmm_E1_resp_etd2), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd2))
```
`Con_Ali_Sam` was removed from extended2 model.

```{r resp etd3 E1}
file_E1_resp_etd3 <- file.path(folder_lmm, "E1_Resp_lmm_etd3.RData")

# fit the etd3 model
if (!file.exists(file_E1_resp_etd3)) {
  glmm_E1_resp_etd3 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + Sam_C + # Con_C + Ali_C + Cue_C + 
         Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_resp_etd3, file = file_E1_resp_etd3)
} else {
  load(file_E1_resp_etd3)
}

print(summary(glmm_E1_resp_etd3), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd3))
```
`Sam_C` was removed from extended3 model.

```{r resp etd4 E1}
file_E1_resp_etd4 <- file.path(folder_lmm, "E1_Resp_lmm_etd4.RData")

# fit the etd4 model
if (!file.exists(file_E1_resp_etd4)) {
  glmm_E1_resp_etd4 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_resp_etd4, file = file_E1_resp_etd4)
} else {
  load(file_E1_resp_etd4)
}

print(summary(glmm_E1_resp_etd4), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd4))
```
`Con_Sam` was removed from extended4 model.

```{r resp etd5 E1}
file_E1_resp_etd5 <- file.path(folder_lmm, "E1_Resp_lmm_etd5.RData")

# fit the etd5 model
if (!file.exists(file_E1_resp_etd5)) {
  glmm_E1_resp_etd5 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + Con_Sam + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_resp_etd5, file = file_E1_resp_etd5)
} else {
  load(file_E1_resp_etd5)
}

print(summary(glmm_E1_resp_etd5), corr = FALSE)
```

#### The optimal model
```{r comapre etd and rdc E1 d}
# compare the extended and reduced model
anova(glmm_E1_resp_etd5, glmm_E1_resp_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_resp_rdc`) explained the data better than the extended model (`glmm_resp_etd5`) and, therefore, the reduced model is used as the optimal model.

```{r the optimal model E1 d}
glmm_E1_resp_opt <- glmm_E1_resp_rdc

print(summary(glmm_E1_resp_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for hit and false alarm
```{r emm E1 resp}
(emm_E1_resp <- emmeans(glmm_E1_resp_opt, ~ Alignment + Congruency + Cue + SameDifferent))
```

#### Estimated marginal means for d'
```{r message=FALSE}
emm_E1_d <- contrast(emm_E1_resp, method = "pairwise", simple = "SameDifferent")
summary(emm_E1_d[1:8], infer = c(TRUE, FALSE), adjust = "none")

# quick check (uncorrected)
# emmip(emm_E1_d, Congruency ~ Alignment | Cue, CIs = TRUE) 
```


```{r plot for publication E1 d slides}
plot_E1_cf_d <- summary(emm_E1_d[1:8], infer = c(TRUE, FALSE), adjust = "sidak") %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed")) +
  scale_color_manual(values=con_color) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(. ~Cue, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Target half", y = expression("Sensitivity"~italic("d'")), fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("***", "", "", "", "*", "", "", ""), color = sig_color, size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E1_cf_d.pdf", plot_E1_cf_d, width = 8, height = 4.8)
plot_E1_cf_d
```

```{r plot for publication E1 d paper}
# ggsave(filename = "E1_cf_d.pdf", 
#        plot_E1_cf_d +
#          theme(legend.position=c(0.5, 0.15)), 
#        width = 7)
```


#### Composite effects
Composite face effects for top and bottom parts:
```{r message=FALSE}
emm_E1_d_cf <- contrast(emm_E1_resp, interaction = "pairwise", by = "Cue")
summary(emm_E1_d_cf[1:2], infer = TRUE)
```

```{r}
emm_E1_d_con <- contrast(emm_E1_resp, interaction = "pairwise", by = c("Cue", "Alignment"))
summary(emm_E1_d_con[c(1,3)], infer = TRUE)
```

#### Facilitation and interference
```{r message=FALSE}
# Sensitivity d'
emm_E1_d_fi <- contrast(emm_E1_resp, interaction = "pairwise", by = c("Cue", "Congruency"), adjust = "sidak")
summary(emm_E1_d_fi[1:4], infer=TRUE)

# # showing the differences between aligned and misaligned (aligned-misaligned)
# emmip(emm_E1_d_fi[1:4], ~ Cue | Congruency, CIs = TRUE, adjust = "sidak") +
#   geom_hline(yintercept = 0, linetype = "dashed")
```

```{r fi E1 d, fig.asp=.65}
plot_E1_cffi_d <- summary(emm_E1_d_fi[1:4], infer=TRUE, adjust = "sidak") %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values=con_color) +
  facet_grid(. ~ Congruency, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_fi_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(italic("d'")~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E1_fi_d.pdf", plot_E1_cffi_d, width = 7, height = 4.55)
plot_E1_cffi_d
```

```{r combined plot d E1, fig.asp=.5}

plot_E1_cf_d_ <- plot_E1_cf_d +
  guides(color = guide_legend(nrow = 1, title.position = "left"), 
         linetype = guide_legend(nrow = 1, title.position = "left")) +
  theme(legend.position = c(0.6, 0.075),
        legend.box = "horizontal") 

plot_E1_d <- ggarrange(plot_E1_cf_d_, plot_E1_cffi_d, 
                       labels = c("A", "B"),
                       font.label = (list(size = 20)),
                       widths = c(1.5, 1),
                       nrow = 1)

# ggsave(filename = "E1_d.pdf", plot_E1_d, width = 10, height = 4.5)
plot_E1_d
```

#### Comparisons between facilitation and interference
```{r}
contrast(emm_E1_d_fi, method = list("faci-inte"=c(1, 1)), by = "Cue")[1:2] %>% 
  summary(infer = TRUE)
```

## Response times
```{r only keep correct trials (but with both same and different trials) E1}
df_lmm_E1_rt <- df_lmm_E1 %>% 
  filter(isCorrect == 1)

# save(df_lmm_E1_rt, file = file.path("data", "df_lmm_E1_rt.RData"))
```

### Fitting the generalized mixed models
with log-transformation.
#### The maximal model
```{r E1 rt max}
# file_E1_rt_max <- file.path(folder_lmm, "E1_rt_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_E1_rt_max)) {
#   glmm_E1_rt_max <- glmer(
#     log(RT) ~ Cue * Congruency * Alignment + 
#       (Cue * Congruency * Alignment | Participant), 
#     family = lognormal(),
#     data = df_lmm_rt,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_E1_rt_max, file = file_E1_rt_max)
# } else {
#   load(file_E1_rt_max)
# }
# 
# print(summary(glmm_E1_rt_max), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r E1 rt zcp}
file_E1_rt_zcp <- file.path(folder_lmm, "E1_rt_lmm_zcp.RData")

# fit the zcp1 model
if (!file.exists(file_E1_rt_zcp)) {
  glmm_E1_rt_zcp <- lmer(
    log(RT) ~ Cue * Congruency * Alignment +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + Con_Ali + 
         Cue_Con_Ali || Participant),
    data = df_lmm_E1_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_rt_zcp, file = file_E1_rt_zcp)
} else {
  load(file_E1_rt_zcp)
}

print(summary(glmm_E1_rt_zcp), corr = FALSE)
```

#### The reduced model
```{r PCA analysis for rt zcp lmm E1}
summary(rePCA(glmm_E1_rt_zcp))
```

`Con_Ali` was removed from extended model (`glmm_E1_rt_zcp`) due to that the variance it explained was smaller than 0.1%, making `glmm_E1_rt_rdc`.

```{r E1 rt rdc}
file_E1_rt_rdc <- file.path(folder_lmm, "E1_rt_lmm_rdc.RData")

# fit the rdc1 model
if (!file.exists(file_E1_rt_rdc)) {
  glmm_E1_rt_rdc <- lmer(
    log(RT) ~ Cue * Congruency * Alignment +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + # Con_Ali + 
         Cue_Con_Ali || Participant),
    data = df_lmm_E1_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_rt_rdc, file = file_E1_rt_rdc)
} else {
  load(file_E1_rt_rdc)
}

print(summary(glmm_E1_rt_rdc), corr = FALSE)
```

#### The extended model
```{r E1 rt etd}
file_E1_rt_etd <- file.path(folder_lmm, "E1_rt_lmm_etd.RData")

# fit the etd1 model
if (!file.exists(file_E1_rt_etd)) {
  glmm_E1_rt_etd <- lmer(
    log(RT) ~ Cue * Congruency * Alignment +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + # Con_Ali + 
         Cue_Con_Ali | Participant),
    data = df_lmm_E1_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_rt_etd, file = file_E1_rt_etd)
} else {
  load(file_E1_rt_etd)
}

print(summary(glmm_E1_rt_etd), corr = FALSE)
```

```{r PCA analysis for E1 rt etd lmm}
summary(rePCA(glmm_E1_rt_etd))
```

`Con_C`, `Ali_C`, and `Cue_Con` were removed from extended model.

```{r E1 rt etd1}
file_E1_rt_etd1 <- file.path(folder_lmm, "E1_rt_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_E1_rt_etd1)) {
  glmm_E1_rt_etd1 <- lmer(
    log(RT) ~ Cue * Congruency * Alignment +  
      (Cue_C + # Con_C + Ali_C + 
         Cue_Ali + # Con_Ali + Cue_Con + 
         Cue_Con_Ali | Participant),
    data = df_lmm_E1_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_rt_etd1, file = file_E1_rt_etd1)
} else {
  load(file_E1_rt_etd1)
}

print(summary(glmm_E1_rt_etd1), corr = FALSE)
```

#### The optimal model
```{r E1 comapre rt etd and rdc}
# compare the extended and reduced model
anova(glmm_E1_rt_etd1, glmm_E1_rt_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_E1_rt_rdc`) explained the data better than the extended model (`glmm_E1_rt_etd1`) and, therefore, the reduced model is used as the optimal model.

```{r E1 the optimal model rt}
glmm_E1_rt_opt <- glmm_E1_rt_rdc

print(summary(glmm_E1_rt_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for RT
```{r E1 emm rt}
file_E1_rt_emm <- file.path(folder_lmm, "E1_rt_emm.RData") 
if (!file.exists(file_E1_rt_emm)) {
  emm_E1_rt <- emmeans(glmm_E1_rt_opt, ~ Cue + Congruency + Alignment)
} else {
  load(file_E1_rt_emm)
}

# emmip(regrid(emm_E1_rt), Congruency ~ Alignment | Cue, CIs = TRUE)

summary(emm_E1_rt, type = "response") # equivalent to regrid(emm_rt)
```

```{r plot for publication E1 rt slides}
plot_E1_cf_rt <- summary(emm_E1_rt, type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(y = response, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  scale_color_manual(values=con_color) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(. ~Cue, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Target half", y = "Correct response times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("", "", "++", "+", "", "", "", ""), color = sig_color, size = 6, nudge_y = 50, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E1_cf_rt.pdf", plot_E1_cf_rt, width = 8, height = 4.8)

plot_E1_cf_rt
```

#### Composite effects
Composite face effects for top and bottom parts:
```{r}
emm_E1_rt_cf <- contrast(regrid(emm_E1_rt), interaction = "pairwise", by = "Cue", infer = TRUE)
emm_E1_rt_cf[1:2]
```

```{r}
emm_E1_rt_con <- contrast(regrid(emm_E1_rt), interaction = "pairwise", by = c("Cue", "Alignment"))
summary(emm_E1_rt_con[c(1,2)], infer = TRUE)
```

#### Facilitation and interference
```{r}
emm_E1_rt_fi <- contrast(regrid(emm_E1_rt), "pairwise", by = c("Cue", "Congruency"), infer=TRUE, adjust = "sidak")

# emmip(emm_E1_rt_fi[1:4], ~ Cue | Congruency, CIs = TRUE, adjust = "sidak")
emm_E1_rt_fi[1:4]
```

```{r fi E1 rt, fig.asp=.65}
plot_E1_cffi_rt <- emm_E1_rt_fi[1:4] %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values=con_color) +
  facet_grid(. ~ Congruency, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_fi_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(RT~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E1_fi_rt.pdf", plot_E1_cffi_rt, width = 7, height = 4.55)
plot_E1_cffi_rt
```

```{r combined plot rt E1, fig.asp=.5}

plot_E1_cf_rt_ <- plot_E1_cf_rt +
  guides(color = guide_legend(nrow = 1, title.position = "left"), 
         linetype = guide_legend(nrow = 1, title.position = "left")) +
  theme(legend.position = c(0.55, 0.075),
        legend.box = "horizontal") 

plot_E1_rt <- ggarrange(plot_E1_cf_rt_, plot_E1_cffi_rt, 
                       labels = c("A", "B"),
                       font.label = (list(size = 20)),
                       widths = c(1.5, 1),
                       nrow = 1)

# ggsave(filename = "E1_rt.pdf", plot_E1_rt, width = 10, height = 4.5)
plot_E1_rt
```

#### Comparisons between facilitation and interference
```{r}
contrast(emm_E1_rt_fi, method = list("faci-inte"=c(1, 1)), by = "Cue")[1:2] %>% 
  summary(infer = TRUE)
```

# Experiment 2
```{r only keep E2}
df_lmm_E2 <- df_lmm %>% 
  filter(Experiment != "109_cue") %>% 
  droplevels() 

contrasts(df_lmm_E2$Probability) <- MASS::contr.sdif(2)

df_lmm_E2 <- df_lmm_E2 %>% 
  mutate(Pro_C = if_else(Probability == 0.25, -0.5, 0.5),
         Cue_Pro = Cue_C * Pro_C,
         Con_Pro = Con_C * Pro_C,
         Ali_Pro = Ali_C * Pro_C,
         Sam_Pro = Sam_C * Pro_C,
         Cue_Con_Pro = Cue_Con * Pro_C,
         Cue_Ali_Pro = Cue_Ali * Pro_C,
         Cue_Sam_Pro = Cue_Sam * Pro_C,
         Con_Ali_Pro = Con_Ali * Pro_C,
         Con_Sam_Pro = Con_Sam * Pro_C,
         Ali_Sam_Pro = Ali_Sam * Pro_C,
         Cue_Con_Ali_Pro = Cue_Con_Ali * Pro_C,
         Cue_Con_Sam_Pro = Cue_Con_Sam * Pro_C,
         Cue_Ali_Sam_Pro = Cue_Ali_Sam * Pro_C,
         Con_Ali_Sam_Pro = Con_Ali_Sam * Pro_C,
         Cue_Con_Ali_Sam_Pro = Cue_Con_Ali_Sam * Pro_C
  )

# save(df_lmm_E2, file = file.path("data", "df_lmm_E2.RData"))
```
There were `r nlevels(df_lmm_E2$Participant)` participants in Experiment 2. 

## Behavioral choices (d')
### Fitting the generalized mixed models
#### The maximal model
```{r E2 resp max d E2}

# file_E2_resp_max <- file.path(folder_lmm, "E2_Resp_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_E2_resp_max)) {
#   glmm_E2_resp_max <- glmer(
#     Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
#       (Cue * Congruency * Alignment * SameDifferent * Probability | Participant), # Con_Ali_Sam
#     family = binomial(link = "probit"),
#     data = df_lmm_E2,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_E2_resp_max, file = file_E2_resp_max)
# } else {
#   load(file_E2_resp_max)
# }
# 
# print(summary(glmm_E2_resp_max), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r resp zcp E2}
file_E2_resp_zcp <- file.path(folder_lmm, "E2_Resp_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file_E2_resp_zcp)) {
  glmm_E2_resp_zcp <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Ali + Con_Sam + Ali_Sam + 
         Cue_Con_Ali + Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam +
         Pro_C + 
         Cue_Pro + Con_Pro + Ali_Pro + Sam_Pro +
         Cue_Con_Pro + Cue_Ali_Pro + Cue_Sam_Pro + Con_Ali_Pro + Con_Sam_Pro + Ali_Sam_Pro + 
         Cue_Con_Ali_Pro + Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + Con_Ali_Sam_Pro + 
         Cue_Con_Ali_Sam_Pro || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E2_resp_zcp, file = file_E2_resp_zcp)
} else {
  load(file_E2_resp_zcp)
}

print(summary(glmm_E2_resp_zcp), corr = FALSE)
```

#### The reduced model
```{r PCA analysis for resp zcp lmm E2}
summary(rePCA(glmm_E2_resp_zcp))
```

`Con_Ali`, `Ali_Sam`, `Cue_Con_Ali`, `Ali_Sam_Pro`, `Con_Ali_Sam_Pro`, `Cue_Con_Pro`, `Cue_Con_Ali_Pro`, `Cue_Ali_Sam`, `Con_Ali_Pro`, `Cue_Con`, `Con_C`, `Con_Pro`, and `Ali_Pro` were removed from extended model (`glmm_E2_resp_zcp`) due to that the variances they explained were smaller than 0.1%, making `glmm_E2_resp_rdc`.

```{r resp rdc E2}
file_E2_resp_rdc <- file.path(folder_lmm, "E2_Resp_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file_E2_resp_rdc)) {
  glmm_E2_resp_rdc <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (Cue_C + Ali_C + Sam_C + # Con_C + 
         Cue_Ali + Cue_Sam + Con_Sam +  # Con_Ali + Ali_Sam + Cue_Con + 
         Cue_Con_Sam + Con_Ali_Sam +  # Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam +
         Pro_C + 
         Cue_Pro + Sam_Pro + # Con_Pro + Ali_Pro + 
         Cue_Ali_Pro + Cue_Sam_Pro + Con_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + 
         Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + 
         Cue_Con_Ali_Sam_Pro || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_rdc, file = file_E2_resp_rdc)
} else {
  load(file_E2_resp_rdc)
}

print(summary(glmm_E2_resp_rdc), corr = FALSE)
```

```{r resp rdc1 E2}
file_E2_resp_rdc1 <- file.path(folder_lmm, "E2_Resp_lmm_rdc1.RData")

# fit the rdc1 model
if (!file.exists(file_E2_resp_rdc1)) {
  ss <- getME(glmm_E2_resp_rdc, c("theta","fixef"))
  glmm_E2_resp_rdc1 <- update(
    glmm_E2_resp_rdc, start=ss,
    control=glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
  # save(glmm_E2_resp_rdc1, file = file_E2_resp_rdc1)
} else {
  load(file_E2_resp_rdc1)
}

print(summary(glmm_E2_resp_rdc1), corr = FALSE)
```

`Ali_C` was further removed.

```{r resp rdc2 E2}
file_E2_resp_rdc2 <- file.path(folder_lmm, "E2_Resp_lmm_rdc2.RData")

# fit the rdc2 model
if (!file.exists(file_E2_resp_rdc2)) {
  glmm_E2_resp_rdc2 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (Cue_C + Sam_C + # Con_C + Ali_C + 
         Cue_Ali + Cue_Sam + Con_Sam +  # Con_Ali + Ali_Sam + Cue_Con + 
         Cue_Con_Sam + Con_Ali_Sam +  # Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam +
         Pro_C + 
         Cue_Pro + Sam_Pro + # Con_Pro + Ali_Pro + 
         Cue_Ali_Pro + Cue_Sam_Pro + Con_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + 
         Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + 
         Cue_Con_Ali_Sam_Pro || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_rdc2, file = file_E2_resp_rdc2)
} else {
  load(file_E2_resp_rdc2)
}

print(summary(glmm_E2_resp_rdc2), corr = FALSE)
```

#### The extended model
```{r resp etd E2}
file_E2_resp_etd <- file.path(folder_lmm, "E2_Resp_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_E2_resp_etd)) {
  glmm_E2_resp_etd <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (Cue_C + Sam_C + # Con_C + Ali_C + 
         Cue_Ali + Cue_Sam + Con_Sam +  # Con_Ali + Ali_Sam + Cue_Con + 
         Cue_Con_Sam + Con_Ali_Sam +  # Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam +
         Pro_C + 
         Cue_Pro + Sam_Pro + # Con_Pro + Ali_Pro + 
         Cue_Ali_Pro + Cue_Sam_Pro + Con_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + 
         Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + 
         Cue_Con_Ali_Sam_Pro | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd, file = file_E2_resp_etd)
} else {
  load(file_E2_resp_etd)
}

print(summary(glmm_E2_resp_etd), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E2_resp_etd))
```

`Sam_Pro`, `Cue_Ali`, `Pro_C`, `Intercept`, `Cue_Ali_Pro`, `Con_Ali_Sam`, `Cue_C`, `Cue_Con_Ali_Sam`, `Con_Sam_Pro`, and `Sam_C` were removed from extended model (`glmm_E2_resp_etd`) due to that the variances they explained were smaller than 1%, making `glmm_E2_resp_etd1`.

```{r resp etd1 E2}
file_E2_resp_etd1 <- file.path(folder_lmm, "E2_Resp_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_E2_resp_etd1)) {
  glmm_E2_resp_etd1 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam + Con_Sam +  # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +  
         # Cue_Con_Ali_Sam +
         # Pro_C + 
         Cue_Pro + # Con_Pro + Ali_Pro + Sam_Pro + 
         Cue_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + Cue_Ali_Pro + Con_Sam_Pro + 
         Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + 
         Cue_Con_Ali_Sam_Pro | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd1, file = file_E2_resp_etd1)
} else {
  load(file_E2_resp_etd1)
}

print(summary(glmm_E2_resp_etd1), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E2_resp_etd1))
```

`Cue_Ali_Sam_Pro`, and `Con_Sam` were removed from extended model (`glmm_E2_resp_etd1`) due to that the variances they explained were smaller than 1%, making `glmm_E2_resp_etd2`.

```{r resp etd2 E2}
file_E2_resp_etd2 <- file.path(folder_lmm, "E2_Resp_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_E2_resp_etd2)) {
  glmm_E2_resp_etd2 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam +  # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + Con_Sam + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +  
         # Cue_Con_Ali_Sam +
         # Pro_C + 
         Cue_Pro + # Con_Pro + Ali_Pro + Sam_Pro + 
         Cue_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + Cue_Ali_Pro + Con_Sam_Pro + 
         Cue_Con_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + Cue_Ali_Sam_Pro + 
         Cue_Con_Ali_Sam_Pro | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd2, file = file_E2_resp_etd2)
} else {
  load(file_E2_resp_etd2)
}

print(summary(glmm_E2_resp_etd2), corr = FALSE)
```

```{r resp etd3 E2}
file_E2_resp_etd3 <- file.path(folder_lmm, "E2_Resp_lmm_etd3.RData")

# fit the etd3 model
if (!file.exists(file_E2_resp_etd3)) {
  
  ss <- getME(glmm_E2_resp_etd2, c("theta","fixef"))
  glmm_E2_resp_etd3 <- update(
    glmm_E2_resp_etd2, start=ss,
    control=glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
  # save(glmm_E2_resp_etd3, file = file_E2_resp_etd3)
} else {
  load(file_E2_resp_etd3)
}

print(summary(glmm_E2_resp_etd3), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E2_resp_etd3))
```

`Cue_Con_Ali_Sam_Pro` was removed from extended model (`glmm_E2_resp_etd3`) due to that the variances it explained were smaller than 1%, making `glmm_E2_resp_etd4`.

```{r resp etd4 E2}
file_E2_resp_etd4 <- file.path(folder_lmm, "E2_Resp_lmm_etd4.RData")

# fit the etd4 model
if (!file.exists(file_E2_resp_etd4)) {
  glmm_E2_resp_etd4 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam +  # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + Con_Sam + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +  
         # Cue_Con_Ali_Sam +
         # Pro_C + 
         Cue_Pro + # Con_Pro + Ali_Pro + Sam_Pro + 
         Cue_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + Cue_Ali_Pro + Con_Sam_Pro + 
         Cue_Con_Sam_Pro # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + Cue_Ali_Sam_Pro + + Cue_Con_Ali_Sam_Pro
       | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd4, file = file_E2_resp_etd4)
} else {
  load(file_E2_resp_etd4)
}

print(summary(glmm_E2_resp_etd4), corr = FALSE)
```

```{r resp etd5 E2}
file_E2_resp_etd5 <- file.path(folder_lmm, "E2_Resp_lmm_etd5.RData")

# fit the etd5 model
if (!file.exists(file_E2_resp_etd5)) {
  
  ss <- getME(glmm_E2_resp_etd4, c("theta","fixef"))
  glmm_E2_resp_etd5 <- update(
    glmm_E2_resp_etd4, start=ss,
    control=glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
  # save(glmm_E2_resp_etd5, file = file_E2_resp_etd5)
} else {
  load(file_E2_resp_etd5)
}

print(summary(glmm_E2_resp_etd5), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E2_resp_etd5))
```

`Cue_Pro` was removed from extended model (`glmm_E2_resp_etd5`) due to that the variances it explained were smaller than 1%, making `glmm_E2_resp_etd6`.

```{r resp etd6 E2}
file_E2_resp_etd6 <- file.path(folder_lmm, "E2_Resp_lmm_etd6.RData")

# fit the etd6 model
if (!file.exists(file_E2_resp_etd6)) {
  glmm_E2_resp_etd6 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam +  # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + Con_Sam + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +  
         # Cue_Con_Ali_Sam +
         # Pro_C + 
         # Con_Pro + Ali_Pro + Sam_Pro + Cue_Pro + 
         Cue_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + Cue_Ali_Pro + Con_Sam_Pro + 
         Cue_Con_Sam_Pro # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + Cue_Ali_Sam_Pro + + Cue_Con_Ali_Sam_Pro
       | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd6, file = file_E2_resp_etd6)
} else {
  load(file_E2_resp_etd6)
}

print(summary(glmm_E2_resp_etd6), corr = FALSE)
```

#### The optimal model
```{r comapre etd and rdc E2 d}
# compare the extended and reduced model
anova(glmm_E2_resp_etd6, glmm_E2_resp_rdc2, refit = FALSE)
```

According to BIC, the reduced model (`glmm_E2_resp_rdc2`) explained the data better than the extended model (`glmm_resp_etd4`) and, therefore, the reduced model is used as the optimal model.

```{r the optimal model E2 d}
glmm_E2_resp_opt <- glmm_E2_resp_rdc2

print(summary(glmm_E2_resp_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for hit and false alarm
```{r emm E2 resp}
(emm_E2_resp <- emmeans(glmm_E2_resp_opt, ~ Alignment + Congruency + Cue + SameDifferent + Probability))
```

#### Estimated marginal means for d'
```{r message=FALSE}
emm_E2_d <- contrast(emm_E2_resp, method = "pairwise", simple = "SameDifferent")
summary(emm_E2_d[1:16], infer = c(TRUE, FALSE), adjust = "none")

# emmip(emm_E2_d, Congruency ~ Alignment | Cue + Probability, CIs = TRUE)
```

```{r plot for publication E2 d slides, fig.asp=.6}
plot_E2_cf_d <- summary(emm_E2_d[1:16], infer = c(TRUE, FALSE), adjust = "sidak") %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  scale_color_manual(values=con_color) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(Probability ~Cue, switch = "x",
             labeller = labeller(Probability = c(`0.25` = "25% cueing top", `0.75` = "75% cueing top"))) +
  coord_cartesian(ylim = ylimit_cf_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Target half", y = expression("Sensitivity"~italic("d'")), fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("***", "", "", "", "*", "", "", "", "***", "", "", "", "", "", "", ""), color = sig_color, size = 6, nudge_y = 0.4, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E2_cf_d.pdf", plot_E2_cf_d, width = 8, height = 4.8)
plot_E2_cf_d
```


#### Composite effects
Composite face effects for top and bottom parts:
```{r message=FALSE}
emm_E2_d_cf <- contrast(emm_E2_resp, interaction = "pairwise", by = c("Cue", "Probability"))
summary(emm_E2_d_cf[1:4], infer = TRUE)
```

```{r}
emm_E2_d_con <- contrast(emm_E2_resp, interaction = "pairwise", by = c("Cue", "Probability", "Alignment"))
summary(emm_E2_d_con[seq(1,7,2)], infer = TRUE)
```

#### Facilitation and interference
```{r message=FALSE}
# Sensitivity d'
emm_E2_d_fi <- contrast(emm_E2_resp, interaction = "pairwise", by = c("Cue", "Congruency", "Probability"), adjust = "sidak")
summary(emm_E2_d_fi[1:8], infer=TRUE)

# emmip(emm_E2_d_fi[1:8], ~ Probability | Cue + Congruency, CIs = TRUE, adjust = "sidak")
```

```{r fi E2 d, fig.asp=.65}
plot_E2_cffi_d <- summary(emm_E2_d_fi[1:8], infer=TRUE) %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values=con_color) +
  facet_grid(Probability ~ Congruency, switch = "x",
             labeller = labeller(Probability = c(`0.25` = "25% cueing top", `0.75` = "75% cueing top"))) +
  coord_cartesian(ylim = ylimit_cf_fi_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(italic("d'")~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E2_fi_d.pdf", plot_E2_cffi_d, width = 7, height = 4.55)
plot_E2_cffi_d
```

```{r combined plot d E2, fig.asp=.5}

plot_E2_cf_d_ <- plot_E2_cf_d +
  guides(color = guide_legend(nrow = 1, title.position = "left"), 
         linetype = guide_legend(nrow = 1, title.position = "left")) +
  theme(legend.position = c(0.6, 0.5),
        legend.box = "horizontal") 

plot_E2_d <- ggarrange(plot_E2_cf_d_, plot_E2_cffi_d, 
                       labels = c("A", "B"),
                       font.label = (list(size = 20)),
                       widths = c(1.5, 1),
                       nrow = 1)

# ggsave(filename = "E2_d.pdf", plot_E2_d, width = 10, height = 7)
plot_E2_d
```

#### Comparisons between facilitation and interference
```{r}
contrast(emm_E2_d_fi, method = list("faci-inte"=c(1, 1)), by = c("Cue", "Probability"))[1:4] %>% 
  summary(infer = TRUE)
```

## Response times
```{r only keep correct trials (but with both same and different trials) E2}
df_lmm_E2_rt <- df_lmm_E2 %>% 
  filter(isCorrect == 1)

# save(df_lmm_E2_rt, file = file.path("data", "df_lmm_E2_rt.RData"))
```

### Fitting the generalized mixed models
with log-transformation.
#### The maximal model
```{r E2 rt max}
# file_E2_rt_max <- file.path(folder_lmm, "E2_rt_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_E2_rt_max)) {
#   glmm_E2_rt_max <- glmer(
#     log(RT) ~ Cue * Congruency * Alignment * Probability + 
#       (Cue * Congruency * Alignment * Probability | Participant), 
#     family = lognormal(),
#     data = df_lmm_rt,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_E2_rt_max, file = file_E2_rt_max)
# } else {
#   load(file_E2_rt_max)
# }
# 
# print(summary(glmm_E2_rt_max), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r E2 rt zcp}
file_E2_rt_zcp <- file.path(folder_lmm, "E2_rt_lmm_zcp.RData")

# fit the zcp1 model
if (!file.exists(file_E2_rt_zcp)) {
  glmm_E2_rt_zcp <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + Con_Ali + 
         Cue_Con_Ali +
         Pro_C +
         Cue_Pro + Con_Pro + Ali_Pro + 
         Cue_Con_Pro + Cue_Ali_Pro + Con_Ali_Pro + 
         Cue_Con_Ali_Pro || Participant),
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_zcp, file = file_E2_rt_zcp)
} else {
  load(file_E2_rt_zcp)
}

print(summary(glmm_E2_rt_zcp), corr = FALSE)
```

#### The reduced model
```{r PCA analysis for rt zcp lmm E2}
summary(rePCA(glmm_E2_rt_zcp))
```

`Cue_Ali`, `Ali_Pro`, `Con_Ali_Pro`, `Con_Pro`, `Cue_Con_Pro`, and `Cue_Con_Ali_Pro` were removed from extended model (`glmm_E2_rt_zcp`) due to that the variance it explained was smaller than 0.1%, making `glmm_E2_rt_rdc`.

```{r E2 rt rdc}
file_E2_rt_rdc <- file.path(folder_lmm, "E2_rt_lmm_rdc.RData")

# fit the rdc1 model
if (!file.exists(file_E2_rt_rdc)) {
  glmm_E2_rt_rdc <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Con_Ali + # Cue_Ali + 
         Cue_Con_Ali +
         Pro_C +
         Cue_Pro +  # Ali_Pro + Con_Pro +
         Cue_Ali_Pro  # Con_Ali_Pro + Cue_Con_Pro + 
          || Participant), # Cue_Con_Ali_Pro
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_rdc, file = file_E2_rt_rdc)
} else {
  load(file_E2_rt_rdc)
}

print(summary(glmm_E2_rt_rdc), corr = FALSE)
```

#### The extended model
```{r E2 rt etd}
file_E2_rt_etd <- file.path(folder_lmm, "E2_rt_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_E2_rt_etd)) {
  glmm_E2_rt_etd <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Con_Ali + # Cue_Ali + 
         Cue_Con_Ali +
         Pro_C +
         Cue_Pro +  # Ali_Pro + Con_Pro +
         Cue_Ali_Pro  # Con_Ali_Pro + Cue_Con_Pro + 
          | Participant), # Cue_Con_Ali_Pro
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_etd, file = file_E2_rt_etd)
} else {
  load(file_E2_rt_etd)
}

print(summary(glmm_E2_rt_etd), corr = FALSE)
```

```{r PCA analysis for E2 rt etd lmm}
summary(rePCA(glmm_E2_rt_etd))
```
`Con_C`, `Ali_C`, `Cue_C`, and `Cue_Ali_Pro` were removed from extended model.

```{r E2 rt etd1}
file_E2_rt_etd1 <- file.path(folder_lmm, "E2_rt_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_E2_rt_etd1)) {
  glmm_E2_rt_etd1 <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      ( # Cue_C + Con_C + Ali_C + 
         Cue_Con + Con_Ali + # Cue_Ali + 
         Cue_Con_Ali +
         Pro_C +
         Cue_Pro  # Ali_Pro + Con_Pro +
           # Con_Ali_Pro + Cue_Con_Pro + Cue_Ali_Pro
          | Participant), # Cue_Con_Ali_Pro
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_etd1, file = file_E2_rt_etd1)
} else {
  load(file_E2_rt_etd1)
}

print(summary(glmm_E2_rt_etd1), corr = FALSE)
```

```{r PCA analysis for E2 rt etd1 lmm}
summary(rePCA(glmm_E2_rt_etd1))
```
`Cue_Con`, `Con_Ali`, and `Cue_Con_Ali` were removed from extended model.

```{r E2 rt etd2}
file_E2_rt_etd2 <- file.path(folder_lmm, "E2_rt_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_E2_rt_etd2)) {
  glmm_E2_rt_etd2 <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      ( # Cue_C + Con_C + Ali_C + 
         # Cue_Ali + Con_Ali + Cue_Con + 
         # Cue_Con_Ali +
         Pro_C +
         Cue_Pro  # Ali_Pro + Con_Pro +
           # Con_Ali_Pro + Cue_Con_Pro + Cue_Ali_Pro
          | Participant), # Cue_Con_Ali_Pro
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_etd2, file = file_E2_rt_etd2)
} else {
  load(file_E2_rt_etd2)
}

print(summary(glmm_E2_rt_etd2), corr = FALSE)
```

#### The optimal model
```{r E2 comapre rt etd and rdc}
# compare the extended and reduced model
anova(glmm_E2_rt_etd2, glmm_E2_rt_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_E2_rt_rdc`) explained the data better than the extended model (`glmm_E2_rt_etd1`) and, therefore, the reduced model is used as the optimal model.

```{r E2 the optimal model rt}
glmm_E2_rt_opt <- glmm_E2_rt_rdc

print(summary(glmm_E2_rt_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for RT
```{r E2 emm rt}
file_E2_rt_emm <- file.path(folder_lmm, "E2_rt_emm.RData") 
if (!file.exists(file_E2_rt_emm)) {
  emm_E2_rt <- emmeans(glmm_E2_rt_opt, ~ Cue + Congruency + Alignment + Probability)
} else {
  load(file_E2_rt_emm)
}

summary(emm_E2_rt, type = "response") # equivalent to regrid(emm_rt)

# emmip(regrid(emm_E2_rt), Congruency ~ Alignment | Cue + Probability, CIs = TRUE)
```

```{r plot for publication E2 rt slides, fig.asp=.6}
plot_E2_cf_rt <- summary(emm_E2_rt, type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(y = response, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  scale_color_manual(values=con_color) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(Probability ~Cue, switch = "x",
             labeller = labeller(Probability = c(`0.25` = "25% cueing top", `0.75` = "75% cueing top"))) +
  coord_cartesian(ylim = ylimit_cf_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Target half", y = "Correct response times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("", "", "**", "***", "", "", "", "", "", "", "*", "*", "", "", "", ""), color = sig_color, size = 6, nudge_y = 50, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E2_cf_rt.pdf", plot_E2_cf_rt, width = 8, height = 4.8)
plot_E2_cf_rt
```

#### Composite effects
Composite face effects for top and bottom parts:
```{r}
emm_E2_rt_cf <- contrast(regrid(emm_E2_rt), interaction = "pairwise", by = c("Cue", "Probability"), infer = TRUE)
emm_E2_rt_cf[1:4]
```

```{r}
emm_E2_rt_con <- contrast(regrid(emm_E2_rt), interaction = "pairwise", by = c("Cue", "Probability", "Alignment"))
summary(emm_E2_rt_con[c(1,2,5,6)], infer = TRUE)
```

#### Facilitation and interference
```{r}
emm_E2_rt_fi <- contrast(regrid(emm_E2_rt), "pairwise", by = c("Cue", "Congruency", "Probability"), infer=TRUE, adjust = "sidak")
emm_E2_rt_fi[1:8]
```

```{r message=FALSE}
# emmip(emm_E2_rt_fi[1:8], ~ Probability | Cue + Congruency, CIs = TRUE, adjust = "sidak") +
#   geom_hline(yintercept = 0, linetype = "dashed")
```

```{r fi E2 rt, fig.asp=.65}
plot_E2_cffi_rt <- emm_E2_rt_fi[1:8] %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values=con_color) +
  facet_grid(Probability ~ Congruency, switch = "x",
             labeller = labeller(Probability = c(`0.25` = "25% cueing top", `0.75` = "75% cueing top"))) +
  coord_cartesian(ylim = ylimit_cf_fi_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(RT~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E2_fi_rt.pdf", plot_E2_cffi_rt, width = 7, height = 4.55)
plot_E2_cffi_rt
```

```{r combined plot rt E2, fig.asp=.5}

plot_E2_cf_rt_ <- plot_E2_cf_rt +
  guides(color = guide_legend(nrow = 1, title.position = "left"), 
         linetype = guide_legend(nrow = 1, title.position = "left")) +
  theme(legend.position = c(0.6, 0.5),
        legend.box = "horizontal") 

plot_E2_rt <- ggarrange(plot_E2_cf_rt_, plot_E2_cffi_rt, 
                       labels = c("A", "B"),
                       font.label = (list(size = 20)),
                       widths = c(1.5, 1),
                       nrow = 1)

# ggsave(filename = "E2_rt.pdf", plot_E2_rt, width = 10, height = 7)
plot_E2_rt
```

#### Comparisons between facilitation and interference
```{r}
contrast(emm_E2_rt_fi, method = list("faci-inte"=c(1, 1)), by = c("Cue", "Probability"))[1:4] %>% 
  summary(infer = TRUE)
```


# Experiment 1 and 2
Results in this section were not included in the manuscript. The results were similar to E1. 
## Behavioral choices (d')
### Fitting the generalized mixed models
#### The maximal model
```{r resp max d}

# file_resp_max <- file.path(folder_lmm, "Resp_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_resp_max)) {
#   glmm_resp_max <- glmer(
#     Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability +
#       (Cue * Congruency * Alignment * SameDifferent | Participant), # Con_Ali_Sam
#     family = binomial(link = "probit"),
#     data = df_lmm,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_resp_max, file = file_resp_max)
# } else {
#   load(file_resp_max)
# }
# 
# print(summary(glmm_resp_max), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r resp zcp}

file_resp_zcp <- file.path(folder_lmm, "Resp_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file_resp_zcp)) {
  glmm_resp_zcp <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Ali + Con_Sam + Ali_Sam +
         Cue_Con_Ali + Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_zcp, file = file_resp_zcp)
} else {
  load(file_resp_zcp)
}

print(summary(glmm_resp_zcp), corr = FALSE)

```

#### The reduced model
```{r PCA analysis for resp zcp lmm}
summary(rePCA(glmm_resp_zcp))
```

`Con_Ali`, `Ali_Sam`, `Cue_Con_Ali`, and `Cue_Ali_Sam` were removed from extended model (`glmm_resp_etd`) due to that the variances they explained were smaller than 0.1%, making `glmm_resp_rdc`.

```{r resp reduced}
file_resp_rdc <- file.path(folder_lmm, "Resp_lmm_rdc.RData")

# fit the zcp model
# three random effects were removed
if (!file.exists(file_resp_rdc)) {
  glmm_resp_rdc <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + 
         Cue_Con_Sam + Con_Ali_Sam +# Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_rdc, file = file_resp_rdc)
} else {
  load(file_resp_rdc)
}

print(summary(glmm_resp_rdc), corr = FALSE)
```

#### The extended model
```{r resp exteded model glmm_resp_rdc}
file_resp_etd <- file.path(folder_lmm, "Resp_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_resp_etd)) {
  glmm_resp_etd <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + 
         Cue_Con_Sam + Con_Ali_Sam +# Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_etd, file = glmm_resp_etd)
} else {
  load(file_resp_etd)
}

print(summary(glmm_resp_etd), corr = FALSE)
```

```{r PCA analysis for resp etd lmm}
summary(rePCA(glmm_resp_etd))
```

`Con_C`, `Cue_Con`, `Ali_C`, and `Cue_Ali` was removed from extended model.

```{r resp exteded1 model}
file_resp_etd1 <- file.path(folder_lmm, "Resp_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_resp_etd1)) {
  glmm_resp_etd1 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Cue_C + Sam_C + # Con_C + Ali_C +
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam + Con_Ali_Sam +# Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_resp_etd1, file = glmm_resp_etd1)
} else {
  load(file_resp_etd1)
}

print(summary(glmm_resp_etd1), corr = FALSE)
```

```{r PCA analysis for resp etd1 lmm}
summary(rePCA(glmm_resp_etd1))
```

`Intercept` was removed from extended1 model.

```{r resp exteded2 model}
file_resp_etd2 <- file.path(folder_lmm, "Resp_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_resp_etd2)) {
  glmm_resp_etd2 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (0 + Cue_C + Sam_C + # Con_C + Ali_C +
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam + Con_Ali_Sam +# Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_etd2, file = glmm_resp_etd2)
} else {
  load(file_resp_etd2)
}

print(summary(glmm_resp_etd2), corr = FALSE)
```

```{r PCA analysis for resp etd2 lmm}
summary(rePCA(glmm_resp_etd2))
```

`Con_Ali_Sam` was removed from extended1 model.

```{r resp exteded3 model}
file_resp_etd3 <- file.path(folder_lmm, "Resp_lmm_etd3.RData")

# fit the etd3 model
if (!file.exists(file_resp_etd3)) {
  glmm_resp_etd3 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (0 + Cue_C + Sam_C + # Con_C + Ali_C +
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_resp_etd3, file = glmm_resp_etd3)
} else {
  load(file_resp_etd3)
}

print(summary(glmm_resp_etd3), corr = FALSE)
```


```{r PCA analysis for resp etd3 lmm}
summary(rePCA(glmm_resp_etd3))
```

`Cue_C` was removed.

```{r resp exteded4 model}
file_resp_etd4 <- file.path(folder_lmm, "Resp_lmm_etd4.RData")

# fit the etd4 model
if (!file.exists(file_resp_etd4)) {
  glmm_resp_etd4 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (0 + Sam_C + # Con_C + Ali_C + Cue_C + 
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_resp_etd4, file = glmm_resp_etd4)
} else {
  load(file_resp_etd4)
}

print(summary(glmm_resp_etd4), corr = FALSE)
```


```{r PCA analysis for resp etd4 lmm}
summary(rePCA(glmm_resp_etd4))
```

`Cue_Con_Ali_Sam` was removed. 

```{r resp exteded5 model}
file_resp_etd5 <- file.path(folder_lmm, "Resp_lmm_etd5.RData")

# fit the etd5 model
if (!file.exists(file_resp_etd5)) {
  glmm_resp_etd5 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (0 + Sam_C + # Con_C + Ali_C + Cue_C + 
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam  # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam + +
          | Participant), # Cue_Con_Ali_Sam
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_resp_etd5, file = glmm_resp_etd5)
} else {
  load(file_resp_etd5)
}

print(summary(glmm_resp_etd5), corr = FALSE)
```

#### The optimal model

```{r comapre etd and rdc d}
# compare the extended and reduced model
anova(glmm_resp_etd5, glmm_resp_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_resp_rdc`) explained the data better than the extended model (`glmm_resp_etd5`) and, therefore, the reduced model is used as the optimal model.

```{r the optimal model d}
glmm_resp_opt <- glmm_resp_rdc

print(summary(glmm_resp_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for hit and false alarm
```{r emm}
(emm_resp <- emmeans(glmm_resp_opt, ~ Alignment + Congruency + Cue + SameDifferent))
```

#### Estimated marginal means for d'
```{r message=FALSE}
emm_d <- contrast(emm_resp, method = "pairwise", simple = "SameDifferent")
summary(emm_d[1:8], infer = c(TRUE, FALSE), adjust = "none")
```

```{r message=FALSE}
# emmip(emm_d, Congruency ~ Alignment | Cue, CIs = TRUE)
```

```{r plot for publication E12 d slides}
plot_E12_cf_d <- summary(emm_d[1:8], infer = c(TRUE, FALSE), adjust = "sidak") %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  scale_color_manual(values=con_color) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(. ~Cue, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Target half", y = expression("Sensitivity"~italic("d'")), fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("***", "", "", "", "**", "", "", ""), color = sig_color, size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E12_cf_d.pdf", plot_E12_cf_d, width = 8, height = 4.8)
plot_E12_cf_d
```

#### Composite effects
Composite face effects for top and bottom parts:
```{r message=FALSE}
emm_d_cf <- contrast(emm_resp, interaction = "pairwise", by = "Cue")
summary(emm_d_cf[1:2], infer = TRUE)
```

```{r}
emm_d_con <- contrast(emm_resp, interaction = "pairwise", by = c("Cue", "Alignment"))
summary(emm_d_con[c(1,3)], infer = TRUE)
```

#### Facilitation and interference
```{r message=FALSE}
# Sensitivity d'
emm_d_fi <- contrast(emm_resp, interaction = "pairwise", by = c("Cue", "Congruency"), adjust = "sidak")
summary(emm_d_fi[1:4], infer=TRUE)
```

```{r message=FALSE}
# showing the differences between aligned and misaligned (aligned-misaligned)
# emmip(emm_d_fi[1:4], ~ Cue | Congruency, CIs = TRUE, adjust = "sidak") +
#   geom_hline(yintercept = 0, linetype = "dashed")
```

```{r fi E12 d}
plot_E12_cffi_d <- summary(emm_d_fi[1:4], infer=TRUE) %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values=con_color) +
  facet_grid(. ~ Congruency, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_fi_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(italic("d'")~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E12_fi_d.pdf", plot_E12_cffi_d, width = 7, height = 4.55)
plot_E12_cffi_d
```

```{r combined plot d E12, fig.asp=.5}

plot_E12_cf_d_ <- plot_E12_cf_d +
  guides(color = guide_legend(nrow = 1, title.position = "left"), 
         linetype = guide_legend(nrow = 1, title.position = "left")) +
  theme(legend.position = c(0.6, 0.075),
        legend.box = "horizontal") 

plot_E12_d <- ggarrange(plot_E12_cf_d_, plot_E12_cffi_d, 
                       labels = c("A", "B"),
                       font.label = (list(size = 20)),
                       widths = c(1.5, 1),
                       nrow = 1)

# ggsave(filename = "E12_d.pdf", plot_E12_d, width = 10, height = 4.5)
plot_E12_d
```

#### Comparisons between facilitation and interference
```{r}
contrast(emm_d_fi, method = list("faci-inte"=c(1, 1)), by = "Cue")[1:2] %>% 
  summary(infer = TRUE)
```

## Response times
```{r only keep correct trials (but with both same and different trials)}
df_lmm_rt <- df_lmm %>% 
  filter(isCorrect == 1)

# save(df_lmm_rt, file = file.path("data", "df_lmm_rt.RData"))
```

### Fitting the generalized mixed models
with log-transformation.
#### The maximal model
```{r rt max}
# file_rt_max <- file.path(folder_lmm, "rt_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_rt_max)) {
#   glmm_rt_max <- glmer(
#     log(RT) ~ Cue * Congruency * Alignment + Probability +
#       (Cue * Congruency * Alignment | Participant), 
#     family = lognormal(),
#     data = df_lmm_rt,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_rt_max, file = file_rt_max)
# } else {
#   load(file_rt_max)
# }
# 
# print(summary(glmm_rt_max), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r rt zcp}

file_rt_zcp <- file.path(folder_lmm, "rt_lmm_zcp.RData")

# fit the zcp1 model
if (!file.exists(file_rt_zcp)) {
  glmm_rt_zcp <- lmer(
    log(RT) ~ Cue * Congruency * Alignment + Probability + 
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + Con_Ali + 
         Cue_Con_Ali || Participant),
    data = df_lmm_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
    # save(glmm_rt_zcp, file = file_rt_zcp)
} else {
    load(file_rt_zcp)
}

print(summary(glmm_rt_zcp), corr = FALSE)

```

#### The reduced model
```{r PCA analysis for rt zcp lmm}
summary(rePCA(glmm_rt_zcp))
```

`Con_Ali`, and `Cue_Ali` were removed from extended model (`glmm_rt_zcp`) due to that the variances they explained were smaller than 0.1%, making `glmm_rt_rdc`.

```{r rt reduced}
file_rt_rdc <- file.path(folder_lmm, "rt_lmm_rdc.RData")

# fit the zcp model
# three random effects were removed
if (!file.exists(file_rt_rdc)) {
  glmm_rt_rdc <- lmer(
    log(RT) ~ Cue * Congruency * Alignment + Probability + 
      (Cue_C + Con_C + Ali_C + 
         Cue_Con +  # Con_Ali + Cue_Ali +
         Cue_Con_Ali || Participant),
    data = df_lmm_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_rt_rdc, file = file_rt_rdc)
} else {
  load(file_rt_rdc)
}

print(summary(glmm_rt_rdc), corr = FALSE)
```

#### The extended model
```{r rt exteded model glmm_rt_etd}
file_rt_etd <- file.path(folder_lmm, "rt_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_rt_etd)) {
   glmm_rt_etd <- lmer(
    log(RT) ~ Cue * Congruency * Alignment + Probability + 
      (Cue_C + Con_C + Ali_C + 
         Cue_Con +  # Con_Ali + Cue_Ali +
         Cue_Con_Ali | Participant),
    data = df_lmm_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_rt_etd, file = glmm_rt_etd)
} else {
  load(file_rt_etd)
}

print(summary(glmm_rt_etd), corr = FALSE)
```

```{r rt exteded1 model}
file_rt_etd1 <- file.path(folder_lmm, "rt_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_rt_etd1)) {
  ss <- getME(glmm_rt_etd, c("theta","fixef"))
  glmm_rt_etd1 <- update(
    glmm_rt_etd, start=ss,
    control=lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
} else {
  load(file_rt_etd1)
}

print(summary(glmm_rt_etd1), corr = FALSE)
```

```{r rePCA for glmm_rt_etd1}
summary(rePCA(glmm_rt_etd1))
```

`Con_C` and `Ali_C` were removed from extended model (`glmm_resp_etd1`) due to that the variances they explained were smaller than 1%, making `glmm_resp_etd2`.

```{r rt exteded model glmm_rt_etd2}
file_rt_etd2 <- file.path(folder_lmm, "rt_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_rt_etd2)) {
  glmm_rt_etd2 <- lmer(
    log(RT) ~ Cue * Congruency * Alignment + Probability + 
      (Cue_C + # Con_C + Ali_C + 
         Cue_Con +  # Con_Ali + Cue_Ali +
         Cue_Con_Ali | Participant),
    data = df_lmm_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_rt_etd2, file = file_rt_etd2)
} else {
  load(file_rt_etd2)
}

print(summary(glmm_rt_etd2), corr = FALSE)
```

#### The optimal model
```{r comapre rt etd and rdc}
# compare the extended and reduced model
anova(glmm_rt_etd2, glmm_rt_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_resp_rdc`) explained the data better than the extended model (`glmm_resp_etd2`) and, therefore, the reduced model is used as the optimal model.

```{r the optimal model rt}
glmm_rt_opt <- glmm_rt_rdc

print(summary(glmm_rt_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for RT
```{r emm rt}
file_rt_emm <- file.path(folder_lmm, "rt_emm.RData") 
if (!file.exists(file_rt_emm)) {
  emm_rt <- emmeans(glmm_rt_opt, ~ Cue + Congruency + Alignment)
} else {
  load(file_rt_emm)
}

summary(emm_rt, type = "response") # equivalent to regrid(emm_rt)
```

```{r}
# emmip(regrid(emm_rt), Congruency ~ Alignment | Cue, CIs = TRUE)
```

```{r plot for publication E12 rt slides, fig.asp=.6}
plot_E12_cf_rt <- summary(emm_rt, type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(y = response, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  scale_color_manual(values=con_color) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(. ~Cue, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Target half", y = "Correct response times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("", "", "***", "***", "", "", "", ""), color = sig_color, size = 6, nudge_y = 50, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E12_cf_rt.pdf", plot_E12_cf_rt, width = 8, height = 4.8)
plot_E12_cf_rt
```


#### Composite effects
Composite face effects for top and bottom parts:
```{r}
emm_rt_cf <- contrast(regrid(emm_rt), interaction = "pairwise", by = "Cue", infer = TRUE)
emm_rt_cf[1:2]
```

```{r message=FALSE}
# emmip(emm_rt_cf[1:2], ~ Cue , CIs = TRUE) +
#   geom_hline(yintercept = 0, linetype = "dashed")
```

```{r}
emm_rt_con <- contrast(regrid(emm_rt), interaction = "pairwise", by = c("Cue", "Alignment"))
summary(emm_rt_con[c(1,2)], infer = TRUE)
```

#### Facilitation and interference
```{r}
emm_rt_fi <- contrast(regrid(emm_rt), "pairwise", by = c("Cue", "Congruency"), infer=TRUE, adjust = "sidak")
emm_rt_fi[1:4]
```

```{r message=FALSE}
# emmip(emm_rt_fi[1:4], ~ Cue | Congruency, CIs = TRUE, adjust = "sidak") +
#   geom_hline(yintercept = 0, linetype = "dashed")
```

```{r fi E12 rt}
plot_E12_cffi_rt <- emm_rt_fi[1:4] %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_color_manual(values=con_color) +
  facet_grid(. ~ Congruency, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_fi_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(RT~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E12_fi_rt.pdf", plot_E12_cffi_rt, width = 7, height = 4.55)
plot_E12_cffi_rt
```

```{r combined plot rt E12, fig.asp=.5}
plot_E12_cf_rt_ <- plot_E12_cf_rt +
  guides(color = guide_legend(nrow = 1, title.position = "left"), 
         linetype = guide_legend(nrow = 1, title.position = "left")) +
  theme(legend.position = c(0.55, 0.075),
        legend.box = "horizontal") 

plot_E12_rt <- ggarrange(plot_E12_cf_rt_, plot_E12_cffi_rt, 
                       labels = c("A", "B"),
                       font.label = (list(size = 20)),
                       widths = c(1.5, 1),
                       nrow = 1)

# ggsave(filename = "E12_rt.pdf", plot_E12_rt, width = 10, height = 4.5)
plot_E12_rt
```

#### Comparisons between facilitation and interference
```{r}
contrast(emm_rt_fi, method = list("faci-inte"=c(1, 1)), by = "Cue")[1:2] %>% 
  summary(infer = TRUE)
```

# Plots for publication
## Experiment 1
```{r fig.asp=1}
plot_E1 <- ggarrange(plot_E1_cf_d_, plot_E1_cffi_d, 
                     plot_E1_cf_rt_, plot_E1_cffi_rt,
                     labels = c("A", "B", "C", "D"),
                     font.label = (list(size = 20)),
                     widths = c(1.5, 1),
                     nrow = 2, ncol = 2)
# ggsave(filename = "E1.pdf", plot_E1, width = 10, height = 9)
plot_E1
```

## Experiment 2
```{r fig.asp=1}
plot_E2 <- ggarrange(plot_E2_cf_d_, plot_E2_cffi_d, 
                     plot_E2_cf_rt_, plot_E2_cffi_rt,
                     labels = c("A", "B", "C", "D"),
                     font.label = (list(size = 20)),
                     widths = c(1.5, 1),
                     nrow = 2, ncol = 2)
# ggsave(filename = "E2.pdf", plot_E2, width = 10, height = 14)
plot_E2
```

## Experiment 1&2
```{r fig.asp=1}
plot_E12 <- ggarrange(plot_E12_cf_d_, plot_E12_cffi_d, 
                     plot_E12_cf_rt_, plot_E12_cffi_rt,
                     labels = c("A", "B", "C", "D"),
                     font.label = (list(size = 20)),
                     widths = c(1.5, 1),
                     nrow = 2, ncol = 2)
# ggsave(filename = "E12.pdf", plot_E12, width = 10, height = 9)
plot_E12
```

# Session information {.unlisted .unnumbered}
```{r}
sessionInfo()
```
